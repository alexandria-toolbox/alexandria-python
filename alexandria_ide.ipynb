{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from warnings import filterwarnings\n",
    "import matplotlib.pyplot as plt\n",
    "import alexandria.console.console_utilities as cu\n",
    "\n",
    "# clear workspace and console (not to be modified)\n",
    "cu.clear_console()\n",
    "filterwarnings('ignore')\n",
    "plt.close('all')\n",
    "\n",
    "# initiate user inputs (not to be modified)\n",
    "user_inputs = {}\n",
    "user_inputs['tab_1'] = {}\n",
    "user_inputs['tab_2_lr'] = {}\n",
    "user_inputs['tab_3'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editable part: tab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model choice (1 = linear regression)\n",
    "user_inputs['tab_1']['model'] = 1\n",
    "\n",
    "# endogenous variables, as list of strings (e.g. ['var1', 'var2'])\n",
    "user_inputs['tab_1']['endogenous_variables'] = ['']\n",
    "\n",
    "# exogenous variables, as list of strings (e.g. ['var1', 'var2']; leave as empty list [] if no exogenous)\n",
    "user_inputs['tab_1']['exogenous_variables'] = ['']\n",
    "\n",
    "# data frequency (1: cross-sectional/undated, 2: yearly, 3: quarterly, 4: monthly, 5: weekly, 6: daily)\n",
    "user_inputs['tab_1']['frequency'] = 1\n",
    "\n",
    "# data sample: start and end periods, as list of timestamps strings (e.g. ['1990-03-31', '2020-12-31']) or periods (e.g. ['1990Q1', '2020Q4'])\n",
    "# either in timestamp format: ['1990-01-31', '2020-12-31'] or in period format: ['1990M1', '2020M12']\n",
    "user_inputs['tab_1']['sample'] = ['', '']\n",
    "\n",
    "# path to project folder, as string (e.g. 'D:\\my_project')\n",
    "user_inputs['tab_1']['project_path'] = os.getcwd()\n",
    "\n",
    "# name of data file, as string (e.g. 'data.csv')\n",
    "user_inputs['tab_1']['data_file'] = 'data.csv'\n",
    "\n",
    "# display progress bar during estimation (True: yes, False: no)\n",
    "user_inputs['tab_1']['progress_bar'] = True\n",
    "\n",
    "# generate estimation graphics (True: yes, False: no)\n",
    "user_inputs['tab_1']['create_graphics'] = True\n",
    "\n",
    "# save estimation results (True: yes, False: no)\n",
    "user_inputs['tab_1']['save_results'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editable part: tab 2, linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this applies only if the selected model is linear regression (model = 1)\n",
    "if user_inputs['tab_1']['model'] == 1:\n",
    "    \n",
    "    # choice of linear regression model (1: maximum likelihood; 2: simple Bayesian;\n",
    "    # 3: hierarchical; 4: independent; 5: heteroscedastic; 6: autocorrelated)\n",
    "    user_inputs['tab_2_lr']['regression_type'] = 1\n",
    "\n",
    "    # post-burn iterations for MCMC algorithm (integer)\n",
    "    user_inputs['tab_2_lr']['iterations'] = 2000\n",
    "\n",
    "    # burnin iterations for MCMC algorithm (integer)\n",
    "    user_inputs['tab_2_lr']['burnin'] = 1000\n",
    "    \n",
    "    # credibility level for model estimates (float between 0 and 1)\n",
    "    user_inputs['tab_2_lr']['model_credibility'] = 0.95\n",
    "\n",
    "    # prior mean for regression coefficients beta: either scalar for common mean (e.g. 0),\n",
    "    # or list of values, one for each coefficient (e.g. [0, 0, 0])\n",
    "    user_inputs['tab_2_lr']['b'] = 0\n",
    "\n",
    "    # prior variance for regression coefficients beta: either scalar for common variance (e.g. 1),\n",
    "    # or list of values, one for each coefficient (e.g. [1, 1, 1])\n",
    "    user_inputs['tab_2_lr']['V'] = 1\n",
    "    \n",
    "    # prior shape for regression variance sigma (positive float)\n",
    "    user_inputs['tab_2_lr']['alpha'] = 0.0001\n",
    "\n",
    "    # prior scale for regression variance sigma (positive float)\n",
    "    user_inputs['tab_2_lr']['delta'] = 0.0001\n",
    "\n",
    "    # prior mean for heteroscedastic coefficients gamma: either scalar for common mean (e.g. 0),\n",
    "    # or list of values, one for each coefficient (e.g. [0, 0, 0])\n",
    "    user_inputs['tab_2_lr']['g'] = 0\n",
    "\n",
    "    # prior variance for heteroscedastic coefficients gamma: either scalar for common variance (e.g. 1),\n",
    "    # or list of values, one for each coefficient (e.g. [1, 1, 1])\n",
    "    user_inputs['tab_2_lr']['Q'] = 100\n",
    "    \n",
    "    # variance of transition kernel for Metropolis-Hastings step in heteroscedastic model (positive float)\n",
    "    user_inputs['tab_2_lr']['tau'] = 0.001\n",
    "\n",
    "    # apply posterior thinning to MCMC draws in heteroscedastic model (True: yes, False: no)\n",
    "    user_inputs['tab_2_lr']['thinning'] = False\n",
    "\n",
    "    # frequency of posterior thinning (positive integer)\n",
    "    user_inputs['tab_2_lr']['thinning_frequency'] = 10\n",
    "\n",
    "    # Z variables, as list of strings (e.g. ['var1', 'var2']); can be empty if model is not heteroscedastic regression\n",
    "    user_inputs['tab_2_lr']['Z_variables'] = ['']\n",
    "    \n",
    "    # order of autoregressive process for residuals in autocorrelated models (positive integer)\n",
    "    user_inputs['tab_2_lr']['q'] = 1\n",
    "    \n",
    "    # prior mean for autocorrelation coefficients phi: either scalar for common mean (e.g. 0),\n",
    "    # or list of values, one value for each coefficient (e.g. [0, 0, 0])\n",
    "    user_inputs['tab_2_lr']['p'] = 0\n",
    "\n",
    "    # prior variance for autocorrelation coefficients phi: either scalar for common variance (e.g. 1),\n",
    "    # or list of values, one value for each coefficient (e.g. [1, 1, 1])\n",
    "    user_inputs['tab_2_lr']['H'] = 100  \n",
    "    \n",
    "    # include constant in regression (True: yes, False: no)\n",
    "    user_inputs['tab_2_lr']['constant'] = True     \n",
    "    \n",
    "    # prior mean for regression constant (float)\n",
    "    user_inputs['tab_2_lr']['b_constant'] = 0\n",
    "\n",
    "    # prior variance for constant (positive float)\n",
    "    user_inputs['tab_2_lr']['V_constant'] = 1   \n",
    "    \n",
    "    # include trend in regression (True: yes, False: no)\n",
    "    user_inputs['tab_2_lr']['trend'] = False\n",
    "    \n",
    "    # prior mean for regression trend (float)\n",
    "    user_inputs['tab_2_lr']['b_trend'] = 0\n",
    "\n",
    "    # prior variance for trend (positive float)\n",
    "    user_inputs['tab_2_lr']['V_trend'] = 1      \n",
    "    \n",
    "    # include quadratic trend in regression (True: yes, False: no)\n",
    "    user_inputs['tab_2_lr']['quadratic_trend'] = False\n",
    "    \n",
    "    # prior mean for regression quadratic trend (float)\n",
    "    user_inputs['tab_2_lr']['b_quadratic_trend'] = 0\n",
    "\n",
    "    # prior variance for quadratic trend (positive float)\n",
    "    user_inputs['tab_2_lr']['V_quadratic_trend'] = 1\n",
    "    \n",
    "    # estimate in-sample fit (True: yes, False: no)\n",
    "    user_inputs['tab_2_lr']['insample_fit'] = False\n",
    "    \n",
    "    # estimate marginal likelihood (True: yes, False: no)\n",
    "    user_inputs['tab_2_lr']['marginal_likelihood'] = False\n",
    "    \n",
    "    # apply hyperparameter optimization (True: yes, False: no)\n",
    "    user_inputs['tab_2_lr']['hyperparameter_optimization'] = False\n",
    "    \n",
    "    # type of hyperparameter optimization (1: common variance, 2: coefficient-specific variances plus residual variance)\n",
    "    user_inputs['tab_2_lr']['optimization_type'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editable part: tab 2, vector autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this applies only if the selected model is vector autoregression (model = 2)\n",
    "if user_inputs['tab_1']['model'] == 2:\n",
    "    \n",
    "    # choice of vector autoregression model (1: maximum likelihood; \n",
    "    # 2: Minnesota; 3: normal-Wishart; 4: independent; 5: dummy observations;\n",
    "    # 6: large Bayesian VAR; 7: proxy-SVAR)\n",
    "    user_inputs['tab_2_var']['var_type'] = 1\n",
    "    \n",
    "    # post-burn iterations for MCMC algorithm (integer)\n",
    "    user_inputs['tab_2_var']['iterations'] = 2000\n",
    "    \n",
    "    # burnin iterations for MCMC algorithm (integer)\n",
    "    user_inputs['tab_2_var']['burnin'] = 1000\n",
    "    \n",
    "    # credibility level for model estimates (float between 0 and 1)\n",
    "    user_inputs['tab_2_var']['model_credibility'] = 0.95\n",
    "    \n",
    "    # include constant in vector autoregression (True: yes, False: no)\n",
    "    user_inputs['tab_2_var']['constant'] = True\n",
    "    \n",
    "    # include trend in vector autoregression (True: yes, False: no)\n",
    "    user_inputs['tab_2_var']['trend'] = False\n",
    "    \n",
    "    # include quadratic trend in regression (True: yes, False: no)\n",
    "    user_inputs['tab_2_var']['quadratic_trend'] = False  \n",
    "    \n",
    "    # endogenous lags to include in vector autoregression\n",
    "    user_inputs['tab_2_var']['lags'] = 4\n",
    "    \n",
    "    # prior autoregressive coefficients: either scalar for common value (e.g. 0.9),\n",
    "    # or list of values, one for each AR coefficient (e.g. [0.9, 0.8, 0.75])\n",
    "    user_inputs['tab_2_var']['ar_coefficients'] = 0.9\n",
    "    \n",
    "    # overall tightness coefficient pi1 (positive float)\n",
    "    user_inputs['tab_2_var']['pi1'] = 0.1\n",
    "    \n",
    "    # cross-variable shrinkage coefficient pi2 (positive float)\n",
    "    user_inputs['tab_2_var']['pi2'] = 0.5\n",
    "    \n",
    "    # lag decay coefficient pi3 (positive float)\n",
    "    user_inputs['tab_2_var']['pi3'] = 1\n",
    "    \n",
    "    # exogenous slackness coefficient pi4 (positive float)\n",
    "    user_inputs['tab_2_var']['pi4'] = 100\n",
    "    \n",
    "    # sums-of-coefficients tightness pi5 (positive float)\n",
    "    user_inputs['tab_2_var']['pi5'] = 1\n",
    "    \n",
    "    # initial observation tightness pi6 (positive float)\n",
    "    user_inputs['tab_2_var']['pi6'] = 0.1 \n",
    "    \n",
    "    # long-run tightness pi7 (positive float)\n",
    "    user_inputs['tab_2_var']['pi7'] = 0.1\n",
    "    \n",
    "    # proxy variables, as list of strings (e.g. ['var1', 'var2']; can be empty if model is not proxy-SVAR\n",
    "    user_inputs['tab_2_var']['proxys'] = ''\n",
    "    \n",
    "    # proxy-SVAR relevance parameter lambda\n",
    "    user_inputs['tab_2_var']['lamda'] = 0.2\n",
    "    \n",
    "    # proxy-SVAR prior type (1: uninformative; 2: Minnesota)\n",
    "    user_inputs['tab_2_var']['proxy_prior'] = 1\n",
    "    \n",
    "    # constrained coefficients (True: yes, False: no)\n",
    "    user_inputs['tab_2_var']['constrained_coefficients'] = False\n",
    "    \n",
    "    # sums-of-coefficients (True: yes, False: no)\n",
    "    user_inputs['tab_2_var']['sums_of_coefficients'] = False\n",
    "    \n",
    "    # dummy initial observation (True: yes, False: no)\n",
    "    user_inputs['tab_2_var']['initial_observation'] = False \n",
    "    \n",
    "    # long-run prior (True: yes, False: no)\n",
    "    user_inputs['tab_2_var']['long_run'] = False  \n",
    "    \n",
    "    # stationary prior (True: yes, False: no)    \n",
    "    user_inputs['tab_2_var']['stationary'] = False\n",
    "    \n",
    "    # marginal likelihood (True: yes, False: no)\n",
    "    user_inputs['tab_2_var']['marginal_likelihood'] = False \n",
    "    \n",
    "    # hyperparameter optimization (True: yes, False: no)\n",
    "    user_inputs['tab_2_var']['hyperparameter_optimization'] = False\n",
    "    \n",
    "    # name of constrained coefficients file, as string (e.g. 'constrained_coefficients.csv')\n",
    "    user_inputs['tab_2_var']['coefficients_file'] = ''\n",
    "    \n",
    "    # name of long-run prior file, as string (e.g. 'long_run.csv')\n",
    "    user_inputs['tab_2_var']['long_run_file'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editable part: tab 2, VEC/VARMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this applies only if the selected model is VEC/VARMA (model = 3)\n",
    "if user_inputs['tab_1']['model'] == 3:\n",
    "    \n",
    "    # choice of model (1: Bayesian Vector Error Correction; \n",
    "    # 2: Bayesian Vector Autoregressive Moving Average)\n",
    "    user_inputs['tab_2_ext']['model'] = 1\n",
    "    \n",
    "    # post-burn iterations for MCMC algorithm (integer)\n",
    "    user_inputs['tab_2_ext']['iterations'] = 2000\n",
    "    \n",
    "    # burnin iterations for MCMC algorithm (integer)\n",
    "    user_inputs['tab_2_ext']['burnin'] = 1000\n",
    "    \n",
    "    # credibility level for model estimates (float between 0 and 1)\n",
    "    user_inputs['tab_2_ext']['model_credibility'] = 0.95    \n",
    "    \n",
    "    # include constant in vector autoregression (True: yes, False: no)\n",
    "    user_inputs['tab_2_ext']['constant'] = True\n",
    "    \n",
    "    # include trend in vector autoregression (True: yes, False: no)\n",
    "    user_inputs['tab_2_ext']['trend'] = False\n",
    "    \n",
    "    # include quadratic trend in regression (True: yes, False: no)\n",
    "    user_inputs['tab_2_ext']['quadratic_trend'] = False      \n",
    "    \n",
    "    # endogenous lags to include in vector error correction\n",
    "    user_inputs['tab_2_ext']['vec_lags'] = 4    \n",
    "    \n",
    "    # vec: overall tightness coefficient pi1 (positive float)\n",
    "    user_inputs['tab_2_ext']['vec_pi1'] = 0.1\n",
    "    \n",
    "    # vec: cross-variable shrinkage coefficient pi2 (positive float)\n",
    "    user_inputs['tab_2_ext']['vec_pi2'] = 0.5\n",
    "    \n",
    "    # vec: lag decay coefficient pi3 (positive float)\n",
    "    user_inputs['tab_2_ext']['vec_pi3'] = 1\n",
    "    \n",
    "    # vec: exogenous slackness coefficient pi4 (positive float)\n",
    "    user_inputs['tab_2_ext']['vec_pi4'] = 100    \n",
    "    \n",
    "    # choice of prior (1: uninformative; 2: horseshoe; 3: selection)\n",
    "    user_inputs['tab_2_ext']['prior_type'] = 1      \n",
    "\n",
    "    # choice of error correction type (1: general; 2: reduced-rank)\n",
    "    user_inputs['tab_2_ext']['error_correction_type'] = 1     \n",
    "\n",
    "    # maximum cointegration rank r (integer between 1 and n)\n",
    "    user_inputs['tab_2_ext']['max_cointegration_rank'] = 1\n",
    "\n",
    "    # endogenous lags to include in vector autoregressive moving average\n",
    "    user_inputs['tab_2_ext']['varma_lags'] = 4\n",
    "    \n",
    "    # varma: prior autoregressive coefficients: either scalar for common value (e.g. 0.9),\n",
    "    # or list of values, one for each AR coefficient (e.g. [0.9, 0.8, 0.75])\n",
    "    user_inputs['tab_2_ext']['ar_coefficients'] = 0.9    \n",
    "    \n",
    "    # varma: overall tightness coefficient pi1 (positive float)\n",
    "    user_inputs['tab_2_ext']['varma_pi1'] = 0.1\n",
    "    \n",
    "    # varma: cross-variable shrinkage coefficient pi2 (positive float)\n",
    "    user_inputs['tab_2_ext']['varma_pi2'] = 0.5\n",
    "    \n",
    "    # varma: lag decay coefficient pi3 (positive float)\n",
    "    user_inputs['tab_2_ext']['varma_pi3'] = 1\n",
    "    \n",
    "    # varma: exogenous slackness coefficient pi4 (positive float)\n",
    "    user_inputs['tab_2_ext']['varma_pi4'] = 100     \n",
    "    \n",
    "    # residual lags to include in vector autoregressive moving average\n",
    "    user_inputs['tab_2_ext']['residual_lags'] = 1\n",
    "    \n",
    "    # varma: overall tightness coefficient lambda1 (positive float)    \n",
    "    user_inputs['tab_2_ext']['lambda1'] = 0.1\n",
    "    \n",
    "    # varma: cross-variable shrinkage coefficient lambda2 (positive float)    \n",
    "    user_inputs['tab_2_ext']['lambda2'] = 0.5\n",
    "    \n",
    "    # varma: lag decay coefficient lambda3 (positive float)    \n",
    "    user_inputs['tab_2_ext']['lambda3'] = 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editable part: tab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate forecasts for the model (True: yes, False: no)\n",
    "user_inputs['tab_3']['forecast'] = False\n",
    " \n",
    "# credibility level for forecast estimates (float between 0 and 1)\n",
    "user_inputs['tab_3']['forecast_credibility'] = 0.95\n",
    "\n",
    "# estimate conditional forecasts for the model (True: yes, False: no)\n",
    "user_inputs['tab_3']['conditional_forecast'] = False    \n",
    "\n",
    "# credibility level for conditional forecast estimates (float between 0 and 1)\n",
    "user_inputs['tab_3']['conditional_forecast_credibility'] = 0.95\n",
    "\n",
    "# estimate impulse response functions for the model (True: yes, False: no)\n",
    "user_inputs['tab_3']['irf'] = False\n",
    "\n",
    "# credibility level for impulse response functions estimates (float between 0 and 1)\n",
    "user_inputs['tab_3']['irf_credibility'] = 0.95\n",
    "\n",
    "# estimate forecast error variance decomposition for the model (True: yes, False: no)\n",
    "user_inputs['tab_3']['fevd'] = False\n",
    "\n",
    "# credibility level for forecast error variance decomposition estimates (float between 0 and 1)\n",
    "user_inputs['tab_3']['fevd_credibility'] = 0.95\n",
    "\n",
    "# estimate historical decomposition for the model (True: yes, False: no)\n",
    "user_inputs['tab_3']['hd'] = False\n",
    "\n",
    "# credibility level for historical decomposition estimates (float between 0 and 1)\n",
    "user_inputs['tab_3']['hd_credibility'] = 0.95\n",
    "\n",
    "# number of forecast periods (positive integer)\n",
    "user_inputs['tab_3']['forecast_periods'] = 1\n",
    "\n",
    "# number of impulse response functions periods (positive integer)\n",
    "user_inputs['tab_3']['irf_periods'] = 1\n",
    "\n",
    "# type of conditional forecasts (1: all shocks, 2: shock-specific)\n",
    "user_inputs['tab_3']['conditional_forecast_type'] = 1\n",
    "\n",
    "# structural identification scheme (1: none, 2: Cholesky)\n",
    "user_inputs['tab_3']['structural_identification'] = 1\n",
    "\n",
    "# estimate forecast evaluation criteria (True: yes, False: no)\n",
    "user_inputs['tab_3']['forecast_evaluation'] = False\n",
    "\n",
    "# name of forecast data file, as string (e.g. 'data_forecast.csv')\n",
    "user_inputs['tab_3']['forecast_file'] = ''\n",
    "\n",
    "# name of structural identification file, as string (e.g. 'structural_identification.csv')\n",
    "user_inputs['tab_3']['structural_identification_file'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code (not to be modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = user_inputs['tab_1']['model']\n",
    "\n",
    "# if model is linear regression, import main code for linear regression, run it, and return model\n",
    "if model == 1:\n",
    "    from alexandria.linear_regression.main import linear_regression_main_code\n",
    "    lr = linear_regression_main_code(user_inputs)\n",
    "    \n",
    "# else, if model is vector autoregression, import main code for vector autoregression, run it, and return model\n",
    "elif model == 2:\n",
    "    from alexandria.vector_autoregression.main import vector_autoregression_main_code\n",
    "    var = vector_autoregression_main_code(user_inputs)\n",
    "\n",
    "# else, if model is vec/varma, import main code for vector autoregression extension, run it, and return model\n",
    "elif model == 3:\n",
    "    from alexandria.vec_varma.main import vec_varma_main_code\n",
    "    model = vec_varma_main_code(user_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
